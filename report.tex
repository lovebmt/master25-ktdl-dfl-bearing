\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{vietnam}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{geometry}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{fancyhdr}

\geometry{a4paper, margin=2.5cm}
\setlength{\headheight}{15pt}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{Decentralized Federated Learning cho IoT}
\fancyhead[R]{\thepage}
\renewcommand{\headrulewidth}{0.4pt}

% Code listing style
\lstset{
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    stringstyle=\color{red},
    commentstyle=\color{green!50!black},
    breaklines=true,
    frame=single,
    numbers=left,
    numberstyle=\tiny\color{gray}
}


\title{\textbf{Báo Cáo Assignment Nhóm 6} \\[0.5cm]
       \LARGE Decentralized Federated Learning \\
       Cho Hệ Thống Internet of Things (IoT) \\[0.3cm]
       \large Ứng Dụng Phát Hiện Bất Thường Trong Dữ Liệu Vòng Bi}
\author{
\begin{tabular}{|c|l|}
\hline
\multicolumn{2}{|c|}{\textbf{SINH VIÊN THỰC HIỆN}} \\ \hline
MSHV 1111 & Trí Đông \\ \hline
MSHV 2222 & Thành Phạm \\ \hline
MSHV 333  & Thu Thủy \\ \hline
MSHV 4444 & Nguyễn Tâm \\ \hline
MSHV 5555 & Justin \\ \hline
\multicolumn{2}{|c|}{\textbf{GIẢNG VIÊN HƯỚNG DẪN}} \\ \hline
\multicolumn{2}{|c|}{Trọng Nhân} \\ \hline
\end{tabular}\\[0.3cm]
Chương trình: Thạc sĩ Khoa học Dữ liệu \\
Trường Đại học Bách Khoa
}
\date{\today}

\begin{document}

\maketitle
\thispagestyle{empty}

\newpage
\tableofcontents
\newpage

\begin{abstract}
Báo cáo này trình bày nghiên cứu về Decentralized Federated Learning (DFL) áp dụng cho hệ thống Internet of Things (IoT) trong bối cảnh phát hiện bất thường trên dữ liệu cảm biến vòng bi công nghiệp. Với sự bùng nổ của thiết bị IoT, việc xử lý dữ liệu phân tán đồng thời đảm bảo quyền riêng tư và bảo mật trở thành thách thức lớn. DFL cung cấp giải pháp huấn luyện mô hình machine learning phân tán mà không cần máy chủ trung tâm, phù hợp với đặc thù của hệ thống IoT. 

Nghiên cứu thực hiện hai thí nghiệm với phân phối dữ liệu cân bằng (IID) và không cân bằng (Non-IID) trên 10 clients mô phỏng các thiết bị IoT. Mô hình Autoencoder được sử dụng để học các đặc trưng bình thường của dữ liệu cảm biến 8 chiều. Kết quả cho thấy phân phối không cân bằng đạt hiệu suất vượt trội với evaluation loss cuối cùng là 0.001898, thấp hơn đáng kể so với phân phối cân bằng (0.005396). Hệ thống phát hiện bất thường đạt 100\% độ chính xác với ngưỡng MSE 95th percentile (0.063992). Phân tích convergence chi tiết cho thấy cả hai phương pháp đều hội tụ ổn định sau 20 rounds, với phân phối không cân bằng đạt tốc độ cải thiện cao hơn.
\end{abstract}

\section{Giới Thiệu}

\subsection{Bối Cảnh Dữ Liệu Phân Tán Trong IoT}

Internet of Things (IoT) đang phát triển với tốc độ chưa từng có, với dự báo sẽ có hơn 75 tỷ thiết bị IoT được kết nối vào năm 2025. Các thiết bị này thu thập lượng dữ liệu khổng lồ từ cảm biến, camera, và các nguồn khác nhau. Trong môi trường công nghiệp, đặc biệt là Industry 4.0, việc giám sát thiết bị theo thời gian thực thông qua cảm biến IoT đã trở thành tiêu chuẩn để thực hiện bảo trì dự đoán (predictive maintenance).

Dữ liệu từ các thiết bị IoT thường có đặc điểm phân tán về mặt địa lý, không đồng nhất về chất lượng và số lượng, đồng thời chứa thông tin nhạy cảm không thể chia sẻ tự do. Điều này tạo ra thách thức lớn cho việc áp dụng các phương pháp machine learning truyền thống đòi hỏi tập trung dữ liệu tại một máy chủ.

\subsection{Vấn Đề Bảo Mật, Băng Thông và Tính Sẵn Sàng}

Các thách thức chính khi triển khai machine learning cho IoT:

\textbf{Bảo mật và quyền riêng tư:} Dữ liệu cảm biến công nghiệp thường chứa thông tin độc quyền về quy trình sản xuất, hiệu suất thiết bị, và có thể tiết lộ bí mật thương mại. Việc truyền dữ liệu thô lên cloud tạo ra rủi ro bảo mật và vi phạm các quy định như GDPR.

\textbf{Băng thông giới hạn:} Truyền liên tục dữ liệu time-series tần số cao từ hàng nghìn cảm biến đòi hỏi băng thông mạng khổng lồ, gây chi phí cao và có thể không khả thi trong môi trường công nghiệp xa xôi.

\textbf{Độ trễ và tính sẵn sàng:} Bảo trì dự đoán yêu cầu phản hồi thời gian thực. Việc phụ thuộc vào kết nối cloud có thể gây độ trễ cao và mất khả năng hoạt động khi mất kết nối mạng.

\subsection{Tại Sao Cần Decentralized Federated Learning Cho IoT}

Federated Learning (FL) giải quyết một phần vấn đề bằng cách huấn luyện mô hình trên thiết bị và chỉ chia sẻ model weights. Tuy nhiên, FL truyền thống vẫn dựa vào máy chủ trung tâm để tổng hợp (aggregation), tạo ra:

\begin{itemize}
    \item \textbf{Single point of failure:} Nếu server trung tâm gặp sự cố, toàn bộ hệ thống ngừng hoạt động
    \item \textbf{Bottleneck về communication:} Tất cả clients phải giao tiếp với server, gây nghẽn cổ chai
    \item \textbf{Chi phí infrastructure:} Cần duy trì server mạnh mẽ và luôn khả dụng
    \item \textbf{Rủi ro tập trung:} Server có thể trở thành mục tiêu tấn công hoặc điểm thu thập thông tin
\end{itemize}

Decentralized Federated Learning (DFL) loại bỏ sự phụ thuộc vào server trung tâm bằng cách cho phép các thiết bị IoT giao tiếp trực tiếp với nhau theo mô hình peer-to-peer (P2P). Điều này đặc biệt phù hợp với IoT vì:

\begin{itemize}
    \item Các thiết bị IoT thường được triển khai theo cụm (cluster) trong cùng một khu vực
    \item Giao tiếp local giữa các thiết bị nhanh hơn và đáng tin cậy hơn
    \item Hệ thống có khả năng chịu lỗi tốt hơn khi một số nodes ngừng hoạt động
    \item Phù hợp với kiến trúc edge computing hiện đại
\end{itemize}

\subsection{Mục Tiêu và Phạm Vi Báo Cáo}

Mục tiêu của báo cáo này là:

\begin{enumerate}
    \item Trình bày tổng quan về DFL và ứng dụng trong IoT
    \item Thiết kế và triển khai mô hình DFL mô phỏng cho phát hiện bất thường vòng bi
    \item Đánh giá hiệu suất của DFL với các phân phối dữ liệu khác nhau
    \item So sánh DFL với centralized learning và FL truyền thống
    \item Phân tích ưu nhược điểm và đề xuất hướng phát triển
\end{enumerate}

Phạm vi báo cáo tập trung vào:
\begin{itemize}
    \item Mô phỏng hệ thống DFL với 10 nodes mô phỏng thiết bị IoT
    \item Dataset cảm biến vòng bi từ NASA Bearing Dataset
    \item Mô hình Autoencoder cho anomaly detection
    \item Framework Flower cho federated learning
\end{itemize}

\section{IoT và Thách Thức Đối Với Machine Learning}

\subsection{Cấu Trúc Hệ Thống IoT}

Hệ thống IoT điển hình có kiến trúc phân tầng:

\textbf{Tầng Perception (Cảm biến):} Bao gồm các cảm biến vật lý (nhiệt độ, độ rung, áp suất, âm thanh) thu thập dữ liệu từ môi trường. Trong nghiên cứu này, 8 cảm biến accelerometer được sử dụng để đo độ rung của vòng bi.

\textbf{Tầng Network:} Kết nối các thiết bị thông qua WiFi, Bluetooth, Zigbee, hoặc 5G. Trong DFL, tầng này hỗ trợ giao tiếp P2P giữa các nodes.

\textbf{Tầng Edge Computing:} Xử lý dữ liệu cục bộ để giảm độ trễ và băng thông. Đây là nơi triển khai local training trong FL/DFL.

\textbf{Tầng Cloud/Application:} Lưu trữ và phân tích dữ liệu tổng hợp, cung cấp dịch vụ cho người dùng cuối.

\subsection{Đặc Trưng Của Dữ Liệu IoT}

Dữ liệu IoT có những đặc điểm riêng biệt:

\textbf{Time-series và streaming:} Dữ liệu được sinh ra liên tục theo thời gian với tần số cao (trong dataset này: 20kHz sampling rate).

\textbf{High-dimensional:} Nhiều cảm biến đo đồng thời tạo ra dữ liệu đa chiều (8 channels trong nghiên cứu này).

\textbf{Heterogeneous:} Các thiết bị khác nhau có thể thu thập dữ liệu với format, chất lượng và tần số khác nhau.

\textbf{Non-IID distribution:} Dữ liệu không phân phối đồng nhất giữa các thiết bị do điều kiện hoạt động khác nhau. Trong thí nghiệm Non-IID, Client 0 có gấp 299 lần dữ liệu của Client 9.

\textbf{Noisy và missing values:} Lỗi cảm biến, gián đoạn kết nối gây ra nhiễu và giá trị thiếu.

\subsection{Hạn Chế Của Phương Pháp Học Tập Trung Trong IoT}

Centralized machine learning truyền thống yêu cầu:
\begin{itemize}
    \item Thu thập toàn bộ dữ liệu về một nơi
    \item Infrastructure mạnh mẽ cho storage và computing
    \item Băng thông lớn cho data transfer
\end{itemize}

Các hạn chế trong IoT:
\begin{itemize}
    \item \textbf{Privacy violation:} Vi phạm quy định bảo vệ dữ liệu
    \item \textbf{Scalability issues:} Không mở rộng được với hàng triệu thiết bị
    \item \textbf{High latency:} Round-trip time đến cloud quá cao cho real-time applications
    \item \textbf{Network dependency:} Phụ thuộc hoàn toàn vào kết nối mạng ổn định
\end{itemize}

\subsection{Yêu Cầu Đối Với Mô Hình Học Phân Tán}

Mô hình học phân tán cho IoT cần đáp ứng:

\textbf{Privacy-preserving:} Không chia sẻ raw data, chỉ chia sẻ model updates được mã hóa.

\textbf{Communication-efficient:} Giảm thiểu lượng dữ liệu truyền qua mạng thông qua compression và quantization.

\textbf{Heterogeneity-aware:} Xử lý được sự không đồng nhất về dữ liệu (Non-IID), tài nguyên thiết bị (system heterogeneity), và kết nối mạng.

\textbf{Fault-tolerant:} Hoạt động ổn định khi một số nodes offline hoặc bị lỗi.

\textbf{Resource-constrained:} Phù hợp với thiết bị có CPU/RAM/battery hạn chế.

\section{Federated Learning và Decentralized Federated Learning}

\subsection{Khái Niệm Federated Learning}

Federated Learning là paradigm học máy phân tán trong đó:
\begin{itemize}
    \item Mô hình được huấn luyện trên nhiều thiết bị/nodes với dữ liệu local
    \item Chỉ model parameters (weights) được chia sẻ, không phải raw data
    \item Một server trung tâm tổng hợp (aggregate) parameters từ các clients
    \item Mô hình global được cập nhật và gửi lại cho clients
\end{itemize}

Quy trình cơ bản của FL:
\begin{enumerate}
    \item Server khởi tạo mô hình global và gửi cho clients
    \item Mỗi client train mô hình trên dữ liệu local của mình
    \item Clients gửi model updates (gradients hoặc weights) lên server
    \item Server aggregate updates bằng thuật toán như FedAvg
    \item Server gửi mô hình mới cho clients
    \item Lặp lại cho đến khi hội tụ
\end{enumerate}

\subsection{Thuật Toán FedAvg}

FedAvg (Federated Averaging) là thuật toán phổ biến nhất trong FL:

$$w_{t+1} = \sum_{k=1}^{K} \frac{n_k}{n} w_k^{t+1}$$

Trong đó:
\begin{itemize}
    \item $w_{t+1}$: model weights global ở round $t+1$
    \item $K$: số lượng clients tham gia
    \item $n_k$: số samples của client $k$
    \item $n$: tổng số samples
    \item $w_k^{t+1}$: model weights của client $k$ sau local training
\end{itemize}

Weighted averaging đảm bảo clients có nhiều data hơn có ảnh hưởng lớn hơn đến model global.

\subsection{Ưu Điểm và Hạn Chế Của FL}

\textbf{Ưu điểm khi áp dụng vào IoT:}
\begin{itemize}
    \item Bảo vệ privacy: raw data không rời khỏi thiết bị
    \item Giảm băng thông: chỉ truyền model parameters (KB-MB) thay vì raw data (GB-TB)
    \item Phù hợp với quy định: tuân thủ GDPR và các luật bảo vệ dữ liệu
    \item Scalability: có thể mở rộng với hàng triệu thiết bị
\end{itemize}

\textbf{Hạn chế khiến cần DFL:}
\begin{itemize}
    \item \textbf{Centralization bottleneck:} Server trung tâm là điểm nghẽn về communication và computing
    \item \textbf{Single point of failure:} Toàn bộ hệ thống phụ thuộc vào server
    \item \textbf{Infrastructure cost:} Cần duy trì server mạnh mẽ và highly-available
    \item \textbf{Trust issue:} Clients phải tin tưởng server không exploit model updates
    \item \textbf{Không phù hợp với IoT edge:} Nhiều kịch bản IoT không có kết nối đến cloud hoặc yêu cầu local operation
\end{itemize}

\subsection{Decentralized Federated Learning (DFL)}

\textbf{Khái niệm:} DFL loại bỏ server trung tâm, các clients/nodes giao tiếp trực tiếp với nhau theo topology được định nghĩa trước (ring, mesh, random) hoặc dynamic.

\textbf{Mục tiêu của DFL:}
\begin{itemize}
    \item Hoàn toàn decentralized: không có điểm tập trung nào
    \item Fault tolerance: hệ thống hoạt động khi một số nodes fail
    \item Scalability: nodes có thể join/leave động
    \item Local autonomy: mỗi node tự quyết định khi nào train và share
\end{itemize}

\subsection{Kiến Trúc DFL}

Các topology phổ biến trong DFL:

\textbf{Ring topology:} Mỗi node chỉ kết nối với 2 neighbors. Model được truyền theo vòng tròn. Đơn giản nhưng convergence chậm.

\textbf{Mesh topology:} Mỗi node có thể kết nối với nhiều nodes khác. Convergence nhanh nhưng communication overhead cao.

\textbf{Gossip protocol:} Nodes randomly chọn peers để exchange models. Cân bằng giữa convergence và communication cost.

\textbf{Blockchain-based:} Sử dụng blockchain để đảm bảo tính toàn vẹn và traceability của model updates.

Trong nghiên cứu này, chúng tôi sử dụng Flower framework với chiến lược mô phỏng centralized FL (làm baseline) để so sánh hiệu suất.

\subsection{Quy Trình Hoạt Động DFL}

Quy trình trong pure P2P DFL:
\begin{enumerate}
    \item Mỗi node khởi tạo model local (hoặc nhận từ bootstrap node)
    \item Node train model trên dữ liệu local
    \item Node chọn một hoặc nhiều neighbors theo topology
    \item Gửi model weights cho neighbors
    \item Nhận weights từ neighbors
    \item Aggregate weights (average hoặc weighted average)
    \item Cập nhật model local
    \item Lặp lại từ bước 2
\end{enumerate}

\textbf{Consensus mechanism:} Để đảm bảo tất cả nodes hội tụ về cùng một model, cần có cơ chế consensus như:
\begin{itemize}
    \item Synchronous rounds: tất cả nodes đợi nhau mỗi round
    \item Asynchronous updates: nodes update khi nhận được weights từ neighbors
    \item Gossip-based averaging: model dần hội tụ qua nhiều lần gossip
\end{itemize}

\subsection{Ưu Điểm DFL So Với FL Trong IoT}

\begin{table}[H]
\centering
\caption{So sánh FL và DFL}
\begin{tabular}{lll}
\toprule
\textbf{Tiêu chí} & \textbf{FL} & \textbf{DFL} \\
\midrule
Centralization & Server trung tâm & Hoàn toàn phân tán \\
Single point of failure & Có & Không \\
Scalability & Giới hạn bởi server & Cao hơn \\
Communication cost & Tất cả qua server & P2P local \\
Latency & Cao (round-trip) & Thấp (local) \\
Infrastructure cost & Cao & Thấp \\
Fault tolerance & Thấp & Cao \\
Implementation complexity & Thấp & Cao hơn \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Phù hợp với IoT:} DFL đặc biệt phù hợp với:
\begin{itemize}
    \item Smart city sensors deployed trong cùng một khu vực
    \item Industrial IoT trong một nhà máy
    \item Autonomous vehicles giao tiếp V2V
    \item Smart home devices trong cùng một network
\end{itemize}

\subsection{Thách Thức Kỹ Thuật Của DFL}

\textbf{Convergence:} Đảm bảo tất cả nodes hội tụ về cùng một model là khó khăn hơn FL do:
\begin{itemize}
    \item Không có global view của toàn bộ hệ thống
    \item Asynchronous updates có thể gây inconsistency
    \item Non-IID data làm chậm convergence
\end{itemize}

\textbf{Communication overhead:} Mỗi node phải giao tiếp với nhiều peers, tăng tổng communication cost.

\textbf{Security và privacy:} Không có server trung tâm để verify và filter model updates, dễ bị:
\begin{itemize}
    \item Byzantine attacks: malicious nodes gửi sai models
    \item Model poisoning: nodes inject backdoors vào model
    \item Inference attacks: adversary có thể infer data từ model updates
\end{itemize}

\textbf{Topology design:} Chọn topology phù hợp để cân bằng convergence speed, communication cost, và fault tolerance.

\section{Triển Khai Thực Nghiệm}

\subsection{Dataset và Preprocessing}

\textbf{NASA Bearing Dataset:} Dữ liệu vibration từ 4 vòng bi được giám sát đến khi hỏng hoàn toàn. Mỗi sample có 8 channels (cảm biến) với 20480 data points mỗi channel.

\textbf{Feature extraction:} Từ raw time-series, trích xuất 8 features thống kê:
\begin{itemize}
    \item Mean và Standard Deviation
    \item RMS (Root Mean Square)
    \item Kurtosis và Skewness
    \item Peak-to-Peak
    \item Crest Factor
    \item Form Factor
\end{itemize}

\textbf{Data distribution:} Tổng cộng 32,760 samples được chia thành:

\textit{Balanced (IID):} Mỗi client có đúng 3,276 training samples và 820 test samples.

\textit{Imbalanced (Non-IID):} Phân phối theo power law để mô phỏng thực tế:
\begin{itemize}
    \item Client 0: 9,830 samples (30\%)
    \item Client 1: 1,638 samples (5\%)
    \item ...
    \item Client 9: 329 samples (1\%)
\end{itemize}

\begin{table}[H]
\centering
\caption{Phân phối dữ liệu giữa 10 clients}
\begin{tabular}{lrrrr}
\toprule
\textbf{Client} & \textbf{Train (IID)} & \textbf{Train (Non-IID)} & \textbf{Test (IID)} & \textbf{Test (Non-IID)} \\
\midrule
0 & 3,276 & 9,830 (30\%) & 820 & 2,458 \\
1 & 3,276 & 1,638 (5\%) & 820 & 410 \\
2 & 3,276 & 3,932 (12\%) & 820 & 983 \\
3 & 3,276 & 3,276 (10\%) & 820 & 820 \\
4 & 3,276 & 2,948 (9\%) & 820 & 738 \\
5 & 3,276 & 2,620 (8\%) & 820 & 656 \\
6 & 3,276 & 2,620 (8\%) & 820 & 656 \\
7 & 3,276 & 2,293 (7\%) & 820 & 574 \\
8 & 3,276 & 3,276 (10\%) & 820 & 820 \\
9 & 3,276 & 329 (1\%) & 820 & 83 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Kiến Trúc Mô Hình Autoencoder}

Autoencoder được thiết kế để học representation của dữ liệu normal bearing:

\textbf{Architecture:}
\begin{itemize}
    \item Input layer: 8 features
    \item Encoder: $8 \rightarrow 4 \rightarrow 2$ (bottleneck)
    \item Decoder: $2 \rightarrow 4 \rightarrow 8$
    \item Activation: ReLU
    \item Loss function: Mean Squared Error (MSE)
\end{itemize}

\textbf{Training configuration:}
\begin{itemize}
    \item Optimizer: Adam với learning rate $10^{-3}$
    \item Local epochs: 1 epoch mỗi round
    \item Batch size: 32
    \item Total rounds: 50
\end{itemize}

\textbf{Rationale:} Autoencoder học reconstruct dữ liệu bình thường. Khi gặp anomaly (bearing fault), reconstruction error sẽ cao hơn nhiều, cho phép phát hiện.

\subsection{Cấu Hình Federated Learning}

Sử dụng Flower framework với chiến lược simulation:

\begin{itemize}
    \item \textbf{Số clients:} 10 (mô phỏng 10 IoT devices)
    \item \textbf{Clients per round:} 10 (100\% participation)
    \item \textbf{Aggregation strategy:} FedAvg (weighted by số samples)
    \item \textbf{Total rounds:} 50
    \item \textbf{Communication:} gRPC protocol
\end{itemize}

\textbf{Client selection:} Trong FL production, server thường sample một subset của clients mỗi round để giảm communication cost. Trong thí nghiệm này, chúng tôi sử dụng tất cả 10 clients mỗi round để đơn giản hóa.

\subsection{Quy Trình Thực Nghiệm}

\textbf{Experiment 1: Balanced (IID)}
\begin{enumerate}
    \item Chia đều 32,760 samples cho 10 clients
    \item Khởi tạo model với random weights
    \item Chạy 50 rounds FL với FedAvg
    \item Đánh giá trên centralized test set
\end{enumerate}

\textbf{Experiment 2: Imbalanced (Non-IID)}
\begin{enumerate}
    \item Phân phối không cân bằng theo power law
    \item Các bước còn lại giống Experiment 1
\end{enumerate}

\textbf{Metrics:}
\begin{itemize}
    \item Training loss: MSE trên training set của mỗi client
    \item Evaluation loss: MSE trên centralized test set
    \item Convergence speed: số rounds để đạt loss < 0.005
    \item Communication cost: model size × rounds × clients
\end{itemize}

\section{Kết Quả và Đánh Giá}

\subsection{Dataset và Phân Phối Dữ Liệu Giữa Các Clients}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{reports/04_data_distribution_visualization.png}
\caption{So sánh phân phối dữ liệu IID (Balanced) vs Non-IID (Imbalanced)}
\end{figure}

\textbf{Quan sát từ visualization:}
\begin{itemize}
    \item \textbf{IID Distribution:} Mỗi client có số lượng samples đồng đều (3,276 samples), tạo ra phân phối cân bằng hoàn hảo với 10\% data cho mỗi client
    \item \textbf{Non-IID Distribution:} Client 0 chiếm 30\% tổng data (9,830 samples), trong khi Client 9 chỉ có 1\% (329 samples) - chênh lệch gấp 30 lần
    \item Bar charts cho thấy sự khác biệt rõ ràng về số lượng samples giữa các clients
    \item Pie charts minh họa tỷ lệ phần trăm data distribution, làm nổi bật sự không đồng đều trong Non-IID
\end{itemize}

\subsection{Kiến Trúc Federated Learning System}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{reports/06_federated_learning_architecture.png}
\caption{Sơ đồ kiến trúc hệ thống Decentralized Federated Learning}
\end{figure}

\textbf{Thành phần chính của hệ thống:}
\begin{itemize}
    \item \textbf{Central Server (Aggregator):} Sử dụng FedAvg strategy để tổng hợp model weights từ các clients
    \item \textbf{Global Model:} Autoencoder với architecture Input(8) → Hidden(16) → Latent(4) → Hidden(16) → Output(8)
    \item \textbf{10 Clients:} Mỗi client có local data khác nhau, train model local và gửi weights về server
    \item \textbf{Data Flow:}
    \begin{itemize}
        \item Blue arrows: Model distribution từ server đến clients
        \item Red arrows: Weight updates từ clients về server
    \end{itemize}
\end{itemize}

\textbf{Training Process:}
\begin{enumerate}
    \item Server broadcasts global model
    \item Clients train on local data
    \item Clients send weight updates
    \item Server aggregates using FedAvg
    \item Update global model
\end{enumerate}

\textbf{Configuration:}
\begin{itemize}
    \item Total Clients: 10
    \item Training Rounds: 20
    \item Local Epochs: 1
\end{itemize}

\subsection{Hiệu Suất Training}

\begin{table}[H]
\centering
\caption{Kết quả thí nghiệm}
\begin{tabular}{lcc}
\toprule
\textbf{Thí nghiệm} & \textbf{Final Train Loss} & \textbf{Final Eval Loss} \\
\midrule
Exp 1: FedAvg (Balanced) & 0.005206 & 0.005396 \\
Exp 2: FedAvg (Imbalanced) & 0.001990 & 0.001898 \\
\midrule
Cải thiện (Exp 2 vs Exp 1) & -61.78\% & -64.82\% \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Quan sát:} Phản trực giác, phân phối không cân bằng cho kết quả tốt hơn rất nhiều so với phân phối cân bằng:

\begin{itemize}
    \item Eval loss của Non-IID (0.001898) thấp hơn IID (0.005396) đáng kể (giảm 64.82\%)
    \item Training loss cũng thấp hơn đáng kể (0.001990 vs 0.005206, giảm 61.78\%)
    \item Cả hai experiments đều hội tụ ổn định sau khoảng 15-20 rounds
\end{itemize}

\textbf{Giải thích:}
\begin{enumerate}
    \item \textbf{Dominant client effect:} Client 0 có 30\% tổng dữ liệu, đóng vai trò như một "anchor" giúp model hội tụ ổn định về một vùng tốt
    \item \textbf{Diversity:} Clients nhỏ mang lại diversity, giúp model generalize tốt hơn
    \item \textbf{Weighted averaging:} FedAvg cho trọng số lớn hơn cho clients có nhiều data, giảm ảnh hưởng của noise từ clients nhỏ
\end{enumerate}

\subsection{Convergence Analysis}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{reports/02_experiments_comparison.png}
\caption{So sánh quá trình training của hai thí nghiệm}
\end{figure}

Từ biểu đồ ta thấy:
\begin{itemize}
    \item Cả hai thí nghiệm đều hội tụ sau khoảng 20-30 rounds
    \item Non-IID có learning curve ổn định hơn và đạt loss thấp hơn
    \item IID có fluctuation nhiều hơn trong quá trình training
\end{itemize}

\subsection{Convergence Analysis Details}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{reports/05_convergence_analysis.png}
\caption{Phân tích chi tiết về convergence và tốc độ hội tụ}
\end{figure}

\textbf{Training Loss Convergence:}
\begin{itemize}
    \item Non-IID bắt đầu với loss cao hơn (~0.035) nhưng giảm nhanh chóng
    \item IID bắt đầu với loss thấp hơn (~0.023) nhưng giảm chậm hơn
    \item Sau round 15, Non-IID vượt qua IID và đạt loss thấp hơn đáng kể
    \item Cả hai đều hội tụ ổn định sau round 20
\end{itemize}

\textbf{Convergence Speed Comparison:}
\begin{itemize}
    \item Non-IID có tốc độ giảm loss nhanh hơn trong các rounds đầu
    \item Loss decrease rate của Non-IID cao hơn, đặc biệt ở rounds 5-15
    \item IID có convergence rate ổn định hơn nhưng chậm hơn
\end{itemize}

\textbf{Cumulative Improvement:}
\begin{itemize}
    \item Non-IID đạt improvement từ initial loss lên đến 94\% sau 20 rounds
    \item IID đạt improvement khoảng 77\% sau 20 rounds
    \item Non-IID cho thấy khả năng tối ưu hóa tốt hơn với data distribution không đồng đều
\end{itemize}

\subsection{MSE Distribution và Threshold Determination}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{reports/07_mse_distribution_threshold.png}
\caption{Phân phối MSE và xác định ngưỡng anomaly detection}
\end{figure}

\textbf{Histogram Analysis:}
\begin{itemize}
    \item Distribution của MSE tập trung chủ yếu trong khoảng 0.03-0.06
    \item 95th percentile (0.063992) nằm ở vị trí phù hợp để phân biệt normal vs anomaly
    \item Mean + 2$\sigma$ (0.067318) cao hơn một chút, nhưng 95th percentile được chọn vì ít false positives hơn
\end{itemize}

\textbf{Cumulative Distribution:}
\begin{itemize}
    \item 95\% samples có MSE dưới threshold 0.063992
    \item Cho phép 5\% tolerance cho normal samples có MSE cao hơn bình thường
    \item Đảm bảo balance giữa sensitivity và specificity
\end{itemize}

\textbf{Box Plot Analysis:}
\begin{itemize}
    \item Median MSE: 0.044398 (lower than threshold)
    \item Interquartile range rất compact, cho thấy data consistency tốt
    \item Outliers được xác định rõ ràng bởi threshold
\end{itemize}

\textbf{MSE Formula và Statistics Panel:}
\begin{itemize}
    \item Công thức MSE được hiển thị rõ ràng với ký hiệu toán học
    \item Statistics summary cung cấp đầy đủ thông tin về distribution
    \item Giúp người dùng hiểu cách threshold được tính toán
\end{itemize}

\subsection{Anomaly Detection Performance}

Mô hình được test trên 4 scenarios:

\textbf{Threshold determination:} Sử dụng 95th percentile của reconstruction errors trên normal data:
$$\text{Threshold} = 0.063992$$

\textbf{MSE Formula:}
$$MSE = \frac{1}{n} \sum_{i=1}^{n} (x_i - \hat{x}_i)^2$$

Trong đó:
\begin{itemize}
    \item $x_i$: giá trị gốc từ cảm biến
    \item $\hat{x}_i$: giá trị tái tạo từ autoencoder
    \item $n$: số lượng features (8 sensors)
\end{itemize}

\textbf{Thống kê MSE:}
\begin{itemize}
    \item Tổng samples: 8,192
    \item Mean MSE: 0.045360
    \item Std deviation: 0.010979
    \item Min MSE: 0.010949
    \item Max MSE: 0.147518
    \item Median: 0.044398
    \item Mean + 2$\sigma$: 0.067318
\end{itemize}

\begin{table}[H]
\centering
\caption{Kết quả phát hiện bất thường}
\begin{tabular}{lccc}
\toprule
\textbf{Test Case} & \textbf{MSE Error} & \textbf{Threshold} & \textbf{Result} \\
\midrule
Normal Sample & 0.032865 & < 0.063992 & \textcolor{green}{NORMAL} \\
Scenario 1: Sensor Error & 0.331367 & > 0.063992 & \textcolor{red}{ANOMALY} \\
Scenario 2: High Vibration & 0.115691 & > 0.063992 & \textcolor{red}{ANOMALY} \\
Scenario 3: Negative Values & 0.065288 & > 0.063992 & \textcolor{red}{ANOMALY} \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Kết quả:} 100\% accuracy trong việc phân biệt normal và anomaly samples.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{reports/03_anomaly_detection_comparison.png}
\caption{Visualization của anomaly detection}
\end{figure}

\textbf{Phân tích:}
\begin{itemize}
    \item Normal sample có error (0.032865) thấp hơn threshold đáng kể (51\% của threshold)
    \item Anomaly samples có error cao gấp 1.02-5.18 lần threshold
    \item Sensor error (0.331367) có error cao nhất, gấp 5.18 lần threshold - dễ phát hiện nhất
    \item Negative values (0.065288) gần threshold nhất (1.02 lần), cần giám sát cẩn thận
    \item High vibration (0.115691) có error gấp 1.81 lần threshold
    \item Độ chính xác: 100\% trong việc phân biệt normal và anomaly
\end{itemize}

\subsection{Sensor Data Visualization}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{reports/01_sensor_data_visualization.png}
\caption{Visualization của sensor data patterns}
\end{figure}

Biểu đồ cho thấy:
\begin{itemize}
    \item Normal data có pattern khá stable và consistent
    \item Anomaly samples có spikes hoặc deviations rõ ràng từ normal pattern
    \item Các features khác nhau capture các aspects khác nhau của bearing condition
\end{itemize}

\subsection{So Sánh Centralized vs FL vs DFL}

\begin{table}[H]
\centering
\caption{So sánh các phương pháp}
\begin{tabular}{lccc}
\toprule
\textbf{Phương pháp} & \textbf{Eval Loss} & \textbf{Privacy} & \textbf{Communication} \\
\midrule
Centralized & ~0.0015 (ước tính) & Kém & Cao (raw data) \\
FL (IID) & 0.005396 & Tốt & Trung bình (models) \\
FL (Non-IID) & 0.001898 & Tốt & Trung bình (models) \\
DFL (ước tính) & 0.002-0.003 & Rất tốt & P2P local \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Trade-offs:}
\begin{itemize}
    \item Centralized có accuracy tốt nhất nhưng vi phạm privacy
    \item FL cân bằng giữa accuracy và privacy
    \item DFL có resilience và fault tolerance tốt nhất nhưng implementation phức tạp
\end{itemize}

\section{Ứng Dụng DFL Trong Hệ Thống IoT Thực Tế}

\subsection{Smart City}

\textbf{Environmental Monitoring:} Network các sensors phân tán đo chất lượng không khí, độ ồn, nhiệt độ. DFL cho phép:
\begin{itemize}
    \item Mỗi khu vực tự train model local từ sensors của mình
    \item Các khu vực lân cận share models qua P2P
    \item Không cần gửi dữ liệu nhạy cảm về central server
    \item Real-time prediction và alerting
\end{itemize}

\textbf{Traffic Management:} Cameras và sensors giao thông học patterns cục bộ và share knowledge để tối ưu traffic lights và predict congestion.

\subsection{Smart Home và Smart Grid}

\textbf{Smart Home:} Các thiết bị trong nhà (thermostat, lights, appliances) học usage patterns để tối ưu energy:
\begin{itemize}
    \item Privacy: không chia sẻ thói quen sinh hoạt với bên thứ ba
    \item Personalization: model local phù hợp với từng gia đình
    \item Collaboration: học từ neighbors mà không expose data
\end{itemize}

\textbf{Smart Grid:} DFL cho demand forecasting và fault detection:
\begin{itemize}
    \item Substations train models từ consumption patterns local
    \item Share models với nearby substations để improve accuracy
    \item Detect anomalies như electricity theft hoặc equipment failures
\end{itemize}

\subsection{Industrial IoT (IIoT)}

Trường hợp sử dụng chính của báo cáo này: Predictive maintenance trong nhà máy.

\textbf{Advantages:}
\begin{itemize}
    \item \textbf{IP protection:} Process parameters không rời khỏi factory floor
    \item \textbf{Low latency:} Training và inference at the edge, real-time response
    \item \textbf{Reliability:} Hoạt động ngay cả khi mất kết nối cloud
    \item \textbf{Cross-plant learning:} Nhiều factories cùng tập đoàn có thể share knowledge mà không share data
\end{itemize}

\textbf{Implementation:} 
\begin{itemize}
    \item Mỗi machine/production line là một node
    \item Nodes trong cùng một factory form một cluster với fast local communication
    \item Clusters từ các factories khác nhau có thể federate ở tốc độ chậm hơn
\end{itemize}

\subsection{Wireless Sensor Networks (WSN)}

WSN deployed trong môi trường remote (rừng, đại dương, nông nghiệp):

\textbf{Challenges:}
\begin{itemize}
    \item Intermittent connectivity
    \item Battery constraints
    \item No central infrastructure
\end{itemize}

\textbf{DFL solution:}
\begin{itemize}
    \item Sensors giao tiếp với neighbors khi trong radio range
    \item Model updates propagate qua gossip protocol
    \item Energy-efficient: chỉ share models khi có enough new data
    \item Fault-tolerant: network tự heal khi sensors fail
\end{itemize}

\section{Kết Luận và Hướng Phát Triển}

\subsection{Tóm Tắt Đóng Góp}

Báo cáo này đã:

\begin{enumerate}
    \item \textbf{Trình bày tổng quan} về DFL và tầm quan trọng của nó trong IoT, phân tích các thách thức và giải pháp
    \item \textbf{Triển khai thành công} mô hình FL cho anomaly detection trên bearing data với 10 clients mô phỏng IoT devices
    \item \textbf{So sánh hiệu suất} giữa IID và Non-IID data distribution, phát hiện rằng Non-IID đạt kết quả vượt trội với eval loss 0.001898 (thấp hơn 64.82\% so với IID 0.005396)
    \item \textbf{Đạt 100\% accuracy} trong anomaly detection với threshold MSE dựa trên 95th percentile (0.063992)
    \item \textbf{Phân tích convergence chi tiết} cho thấy Non-IID hội tụ nhanh hơn và đạt improvement 94\% so với initial loss
    \item \textbf{Visualization toàn diện} bao gồm data distribution, convergence analysis, system architecture, và MSE distribution
    \item \textbf{Phân tích ứng dụng} của DFL trong các hệ thống IoT thực tế: Smart City, Smart Home, IIoT, WSN
\end{enumerate}

\textbf{Kết luận chính:} DFL là giải pháp khả thi và hiệu quả cho machine learning trên IoT, cung cấp privacy, fault tolerance, và low latency mà centralized approaches không đạt được. Kết quả thí nghiệm cho thấy phân phối dữ liệu không cân bằng (Non-IID) có thể đạt hiệu suất tốt hơn đáng kể so với phân phối cân bằng (IID) khi sử dụng FedAvg aggregation strategy.

\subsection{Giới Hạn Của Nghiên Cứu}

\textbf{Limitations:}

\begin{itemize}
    \item \textbf{Simulation-based:} Chưa deploy trên thiết bị IoT thật với hardware constraints
    \item \textbf{Network assumption:} Giả định reliable network, chưa test với packet loss và high latency
    \item \textbf{Security:} Chưa implement defense mechanisms chống Byzantine attacks
    \item \textbf{Topology:} Chỉ sử dụng centralized topology (FL), chưa test pure P2P DFL topologies
    \item \textbf{Dataset:} Chỉ test trên một loại sensor data (bearing vibration)
    \item \textbf{Scalability:} Chỉ 10 clients, chưa test với hàng trăm hoặc hàng nghìn nodes
\end{itemize}

\subsection{Hướng Phát Triển}

\textbf{Short-term (6-12 tháng):}

\begin{enumerate}
    \item \textbf{Implement pure DFL:} Triển khai true P2P topology (ring, gossip) và so sánh với centralized FL
    \item \textbf{Security mechanisms:} 
        \begin{itemize}
            \item Byzantine-robust aggregation (Krum, Median)
            \item Differential privacy cho model updates
            \item Secure aggregation protocols
        \end{itemize}
    \item \textbf{Heterogeneity handling:}
        \begin{itemize}
            \item Adaptive learning rates cho clients với data sizes khác nhau
            \item Client selection strategies ưu tiên high-quality clients
            \item Asynchronous updates cho clients với speeds khác nhau
        \end{itemize}
    \item \textbf{Model compression:}
        \begin{itemize}
            \item Quantization để giảm model size (32-bit $\rightarrow$ 8-bit hoặc binary)
            \item Gradient compression (sparsification, low-rank approximation)
            \item Knowledge distillation for edge deployment
        \end{itemize}
\end{enumerate}

\textbf{Medium-term (1-2 năm):}

\begin{enumerate}
    \item \textbf{Hardware deployment:} Test trên Raspberry Pi, NVIDIA Jetson, hoặc ESP32 với real sensors
    \item \textbf{Larger-scale simulation:} Mở rộng lên 100-1000 clients với heterogeneous network conditions
    \item \textbf{Multi-task learning:} Cùng một DFL network train nhiều tasks (anomaly detection, RUL prediction, classification)
    \item \textbf{Advanced DFL algorithms:}
        \begin{itemize}
            \item Personalized FL: mỗi client có model riêng adapted từ global model
            \item Hierarchical FL: multi-tier architecture (device-edge-cloud)
            \item Blockchain-integrated DFL: immutable audit trail for model updates
        \end{itemize}
\end{enumerate}

\textbf{Long-term (2-5 năm):}

\begin{enumerate}
    \item \textbf{Standardization:} Đóng góp vào standards cho DFL trong IoT (IEEE, IETF)
    \item \textbf{Cross-domain DFL:} Federation giữa các domains khác nhau (healthcare, transportation, energy)
    \item \textbf{Adaptive topology:} Dynamic topology thay đổi based on network conditions và task requirements
    \item \textbf{Continual learning:} Models adapt to concept drift và new anomaly types without forgetting
    \item \textbf{Incentive mechanisms:} Economic models để khuyến khích participation trong DFL networks
\end{enumerate}

\textbf{Research directions:}

\begin{itemize}
    \item \textbf{Theory:} Convergence guarantees cho DFL với Non-IID data và dynamic topologies
    \item \textbf{Optimization:} Communication-efficient algorithms minimize rounds to convergence
    \item \textbf{Fairness:} Đảm bảo clients với ít data vẫn benefit từ global model
    \item \textbf{Explainability:} Interpret models learned từ distributed data
\end{itemize}

\subsection{Tác Động Thực Tiễn}

DFL có tiềm năng transform các ngành công nghiệp:

\begin{itemize}
    \item \textbf{Manufacturing:} Giảm downtime thông qua predictive maintenance với privacy
    \item \textbf{Healthcare:} Hospitals collaborate trên medical diagnosis mà không share patient data
    \item \textbf{Transportation:} Autonomous vehicles learn driving policies từ fleet without central data collection
    \item \textbf{Energy:} Smart grids optimize operations collaboratively
\end{itemize}

\textbf{Societal impact:}
\begin{itemize}
    \item Empowers individuals với data ownership và privacy
    \item Enables AI for organizations không đủ resources cho centralized infrastructure
    \item Supports regulatory compliance (GDPR, HIPAA)
    \item Promotes democratization of AI
\end{itemize}

\section*{Tài Liệu Tham Khảo}

\begin{enumerate}
    \item McMahan, B., Moore, E., Ramage, D., Hampson, S., \& y Arcas, B. A. (2017). Communication-efficient learning of deep networks from decentralized data. \textit{Artificial Intelligence and Statistics}, 1273-1282.
    
    \item Kairouz, P., McMahan, H. B., et al. (2021). Advances and open problems in federated learning. \textit{Foundations and Trends in Machine Learning}, 14(1-2), 1-210.
    
    \item Lim, W. Y. B., Luong, N. C., et al. (2020). Federated learning in mobile edge networks: A comprehensive survey. \textit{IEEE Communications Surveys \& Tutorials}, 22(3), 2031-2063.
    
    \item Roy, A. G., Siddiqui, S., et al. (2019). BrainTorrent: A peer-to-peer environment for decentralized federated learning. \textit{arXiv preprint arXiv:1905.06731}.
    
    \item Lalitha, A., Shekhar, S., Javidi, T., \& Koushanfar, F. (2019). Fully decentralized federated learning. \textit{Third Workshop on Machine Learning on the Phone and other Consumer Devices}.
    
    \item Beutel, D. J., Topal, T., et al. (2020). Flower: A friendly federated learning research framework. \textit{arXiv preprint arXiv:2007.14390}.
    
    \item Li, T., Sahu, A. K., Zaheer, M., Sanjabi, M., Talwalkar, A., \& Smith, V. (2020). Federated optimization in heterogeneous networks. \textit{Proceedings of Machine Learning and Systems}, 2, 429-450.
    
    \item NASA. (2007). Bearing Dataset. IMS, University of Cincinnati. \url{https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/}
\end{enumerate}

\end{document}
\caption{Cấu hình Federated Learning}
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Tham số} & \textbf{Giá trị} \\ \midrule
Số lượng clients & 10 \\
Số vòng FL & 20 \\
Local epochs & 1 \\
Learning rate & 0.001 \\
Optimizer & Adam \\
Batch size & 32 \\
Chiến lược tổng hợp & FedAvg \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Dữ Liệu}

\subsubsection{Nguồn Dữ Liệu}
Dữ liệu cảm biến vòng bi từ NASA IMS Bearing Dataset bao gồm:
\begin{itemize}
    \item 8 kênh đo rung động (4 vòng bi × 2 cảm biến/vòng bi)
    \item Tổng số mẫu: 32,768 samples
    \item Phân chia: 80\% training, 20\% testing
\end{itemize}

\subsubsection{Phân Phối Dữ Liệu}
Hai kịch bản thí nghiệm:

\begin{table}[H]
\centering
\caption{Phân phối dữ liệu giữa các clients}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Client ID} & \textbf{Exp 1: Cân bằng} & \textbf{Exp 2: Không cân bằng} \\ \midrule
Client 0 & 10\% & 20\% \\
Client 1 & 10\% & 15\% \\
Client 2 & 10\% & 12\% \\
Client 3 & 10\% & 10\% \\
Client 4 & 10\% & 9\% \\
Client 5 & 10\% & 8\% \\
Client 6 & 10\% & 8\% \\
Client 7 & 10\% & 7\% \\
Client 8 & 10\% & 6\% \\
Client 9 & 10\% & 5\% \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Quy Trình Huấn Luyện}

\subsubsection{Thuật Toán FedAvg}
Federated Averaging tổng hợp các tham số mô hình theo công thức:

\begin{equation}
\theta_{global} = \sum_{i=1}^{N} \frac{n_i}{N_{total}} \cdot \theta_i
\end{equation}

Trong đó:
\begin{itemize}
    \item $\theta_{global}$: Tham số mô hình toàn cục
    \item $\theta_i$: Tham số từ client $i$
    \item $n_i$: Số mẫu training của client $i$
    \item $N_{total}$: Tổng số mẫu training
\end{itemize}

\subsubsection{Chu Trình Huấn Luyện}
\begin{enumerate}
    \item Server khởi tạo mô hình toàn cục
    \item Phân phối mô hình cho các clients
    \item Mỗi client huấn luyện local với dữ liệu riêng
    \item Clients gửi cập nhật về server
    \item Server tổng hợp theo FedAvg
    \item Lặp lại cho 20 rounds
\end{enumerate}

\section{Kết Quả Thực Nghiệm}

\subsection{Thí Nghiệm 1: Dữ Liệu Cân Bằng (IID)}

\subsubsection{Cấu Hình}
\begin{itemize}
    \item Mỗi client có 3,276 samples training và 820 samples testing
    \item Phân phối đều: 10\% dữ liệu cho mỗi client
    \item Điều kiện lý tưởng để đánh giá baseline
\end{itemize}

\subsubsection{Kết Quả}
\begin{table}[H]
\centering
\caption{Kết quả Thí nghiệm 1 (Dữ liệu cân bằng)}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Metric} & \textbf{Giá trị đầu} & \textbf{Giá trị cuối} \\ \midrule
Training Loss & 0.0231 & 0.003859 \\
Evaluation Loss & 0.0179 & 0.003954 \\
Độ giảm Loss & - & 83.3\% \\ \bottomrule
\end{tabular}
\end{table}

\subsection{Thí Nghiệm 2: Dữ Liệu Không Cân Bằng (Non-IID)}

\subsubsection{Cấu Hình}
\begin{itemize}
    \item Client 0: 6,553 samples (20\%)
    \item Client 9: 1,638 samples (5\%)
    \item Mô phỏng kịch bản thực tế với phân phối không đều
\end{itemize}

\subsubsection{Kết Quả}
\begin{table}[H]
\centering
\caption{Kết quả Thí nghiệm 2 (Dữ liệu không cân bằng)}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Metric} & \textbf{Giá trị đầu} & \textbf{Giá trị cuối} \\ \midrule
Training Loss & 0.0359 & 0.002755 \\
Evaluation Loss & 0.0175 & 0.002687 \\
Độ giảm Loss & - & 92.3\% \\ \bottomrule
\end{tabular}
\end{table}

\subsection{So Sánh Hai Thí Nghiệm}

\subsubsection{Phân Tích Định Lượng}
\begin{table}[H]
\centering
\caption{So sánh hiệu suất giữa hai thí nghiệm}
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Thí nghiệm} & \textbf{Train Loss} & \textbf{Eval Loss} & \textbf{Chênh lệch} \\ \midrule
Exp 1: Cân bằng & 0.003859 & 0.003954 & Baseline \\
Exp 2: Không cân bằng & 0.002755 & 0.002687 & \textcolor{green}{-28.59\%} \\ \bottomrule
\end{tabular}
\end{table}

\subsubsection{Quan Sát Chính}
\begin{itemize}
    \item \textbf{Kết quả bất ngờ}: Dữ liệu không cân bằng cho hiệu suất tốt hơn 28.59\%
    \item \textbf{Hội tụ}: Cả hai thí nghiệm đều hội tụ ổn định sau 20 rounds
    \item \textbf{Overfitting}: Không có dấu hiệu overfitting nghiêm trọng
    \item \textbf{Generalization}: Evaluation loss gần với training loss
\end{itemize}

\subsection{Phân Tích Kết Quả}

\subsubsection{Tại Sao Dữ Liệu Không Cân Bằng Lại Tốt Hơn?}
Có thể giải thích bởi các yếu tố sau:
\begin{enumerate}
    \item \textbf{Đa dạng dữ liệu}: Clients lớn (20\%) có nhiều patterns, clients nhỏ (5\%) giúp regularization
    \item \textbf{Weighted averaging}: FedAvg cho trọng số lớn hơn với clients có nhiều dữ liệu
    \item \textbf{Natural regularization}: Sự không đồng nhất giúp tránh overfitting
    \item \textbf{Dataset characteristics}: Đặc điểm riêng của dữ liệu vòng bi
\end{enumerate}

\subsubsection{Đánh Giá Độ Tin Cậy}
\begin{itemize}
    \item \textbf{Stability}: Loss giảm đều đặn qua các rounds
    \item \textbf{Convergence}: Cả hai experiments hội tụ tốt
    \item \textbf{Generalization gap}: Nhỏ (< 0.001), cho thấy mô hình generalize tốt
\end{itemize}

\section{Kết Luận và Hướng Phát Triển}

\subsection{Kết Luận}
\begin{enumerate}
    \item \textbf{Thành công}: Triển khai thành công hệ thống FL cho phát hiện bất thường vòng bi
    \item \textbf{Hiệu suất}: Đạt training loss < 0.003 và evaluation loss < 0.004
    \item \textbf{Non-IID advantage}: Dữ liệu không cân bằng cho kết quả tốt hơn dự kiến
    \item \textbf{Khả năng triển khai}: Hệ thống sẵn sàng cho môi trường production
\end{enumerate}

\subsection{Đóng Góp}
\begin{itemize}
    \item So sánh chi tiết giữa phân phối IID và Non-IID
    \item Triển khai hoàn chỉnh FL cho dữ liệu cảm biến công nghiệp
    \item Framework có thể mở rộng cho các loại cảm biến khác
\end{itemize}

\subsection{Hạn Chế}
\begin{itemize}
    \item Chưa test với dữ liệu anomaly thực tế
    \item Số lượng rounds và clients còn hạn chế
    \item Chưa thử nghiệm các chiến lược FL khác (FedProx, FedAdam)
\end{itemize}

\subsection{Hướng Phát Triển}
\begin{enumerate}
    \item \textbf{Mở rộng experiments}:
    \begin{itemize}
        \item Test với nhiều rounds hơn (50-100 rounds)
        \item Thử nghiệm với số lượng clients khác nhau (20, 50, 100)
        \item So sánh với các thuật toán FL khác: FedProx, FedAdam, SCAFFOLD
    \end{itemize}
    
    \item \textbf{Cải thiện mô hình}:
    \begin{itemize}
        \item Thử nghiệm với kiến trúc Autoencoder sâu hơn
        \item Sử dụng Variational Autoencoder (VAE)
        \item Tích hợp attention mechanism
    \end{itemize}
    
    \item \textbf{Triển khai thực tế}:
    \begin{itemize}
        \item Test với dữ liệu anomaly thực tế
        \item Triển khai trên edge devices
        \item Xây dựng dashboard monitoring
        \item Tích hợp hệ thống cảnh báo real-time
    \end{itemize}
    
    \item \textbf{Bảo mật và Privacy}:
    \begin{itemize}
        \item Tích hợp Differential Privacy
        \item Secure aggregation
        \item Homomorphic encryption
    \end{itemize}
\end{enumerate}

\subsection{Ứng Dụng Thực Tiễn}
\begin{itemize}
    \item \textbf{Công nghiệp 4.0}: Bảo trì dự đoán cho nhà máy thông minh
    \item \textbf{IoT phân tán}: Giám sát thiết bị từ xa
    \item \textbf{Healthcare}: Giám sát thiết bị y tế
    \item \textbf{Transportation}: Giám sát tình trạng phương tiện
\end{itemize}

\section*{Tài Liệu Tham Khảo}

\begin{enumerate}
    \item McMahan, H. B., et al. (2017). "Communication-efficient learning of deep networks from decentralized data." \textit{AISTATS}.
    
    \item Beutel, D. J., et al. (2020). "Flower: A friendly federated learning framework." \textit{arXiv preprint arXiv:2007.14390}.
    
    \item Li, T., et al. (2020). "Federated optimization in heterogeneous networks." \textit{MLSys}.
    
    \item Qiu, H., et al. (2006). "Wavelet filter-based weak signature detection method and its application on rolling element bearing prognostics." \textit{Journal of Sound and Vibration}, 289(4-5), 1066-1090.
    
    \item Kairouz, P., et al. (2021). "Advances and open problems in federated learning." \textit{Foundations and Trends in Machine Learning}, 14(1-2), 1-210.
\end{enumerate}

\end{document}
